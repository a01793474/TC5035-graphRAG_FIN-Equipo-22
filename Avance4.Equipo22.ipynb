{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a5fd823d-c64e-4a2d-a01f-67e52191045e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from pathlib import Path\n",
    "from typing import List\n",
    "\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_community.graphs import Neo4jGraph\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings, AzureOpenAIEmbeddings, AzureChatOpenAI\n",
    "from langchain_text_splitters import TokenTextSplitter\n",
    "from neo4j.exceptions import ClientError\n",
    "\n",
    "import openai\n",
    "from openai import OpenAI\n",
    "from openai import AzureOpenAI\n",
    "\n",
    "from time import sleep\n",
    "#from string import Template\n",
    "#import json\n",
    "#from neo4j import GraphDatabase\n",
    "#import glob\n",
    "#from timeit import default_timer as timer\n",
    "#from time import sleep\n",
    "#import logging\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8bc09045-f9dc-4d05-a963-71d49ec5fd9e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load environment variables\n",
    "load_dotenv(r\"C:\\Users\\lriospie\\OneDrive - azureford\\Documents\\Maestria\\Integrador\\Neo4j_RAG\\.env\",verbose=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f9a98868-d5ea-45e7-b66c-7f6e91ae0f46",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# client = AzureOpenAI(\n",
    "#     api_key=os.getenv(\"AZURE_OPENAI_API_KEY\"), \n",
    "#     api_version=\"2023-05-15\",\n",
    "#     azure_endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "# )\n",
    "\n",
    "\n",
    "AZURE_OPENAI_ENDPOINT=os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "AZURE_OPENAI_API_KEY=os.getenv(\"AZURE_OPENAI_API_KEY\"), \n",
    "\n",
    "#deployment_name='text-embedding-3' #This will correspond to the custom name you chose for your deployment when you deployed a model.\n",
    "\n",
    "# Embeddings & LLM models\n",
    "embedding_dimension = 1536\n",
    "embeddings = AzureOpenAIEmbeddings(azure_deployment=\"text-embedding-3\",api_version=\"2024-02-01\",dimensions=embedding_dimension)\n",
    "\n",
    "llm = AzureChatOpenAI(azure_deployment='chat_gtp_35',api_version=\"2023-05-15\", temperature=0)\n",
    "\n",
    "# Get Neo4j credentials from environment variables\n",
    "NEO4J_URI=os.getenv(\"NEO4J_URI\")\n",
    "NEO4J_USERNAME=os.getenv(\"NEO4J_USER\")\n",
    "NEO4J_PASSWORD=os.getenv(\"NEO4J_PASSWORD\")\n",
    "\n",
    "graph = Neo4jGraph()\n",
    "sleep(5)\n",
    "graph.query(\"MATCH (n) DETACH DELETE n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "599e9be0-c94a-4c3d-bb0b-2e1ad2f53877",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load the text file\n",
    "txt_path =\"./News_canab.txt\"\n",
    "#loader = TextLoader(str(txt_path))\n",
    "loader = TextLoader(str(txt_path), encoding='utf-8')\n",
    "documents = loader.load()\n",
    "\n",
    "# Ingest Parent-Child node pairs\n",
    "parent_splitter = TokenTextSplitter(chunk_size=384, chunk_overlap=24)\n",
    "child_splitter = TokenTextSplitter(chunk_size=75, chunk_overlap=24)\n",
    "parent_documents = parent_splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "903a5e34-3430-43b5-9eb3-6453ae4d7709",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for i, parent in enumerate(parent_documents):\n",
    "    child_documents = child_splitter.split_documents([parent])\n",
    "    params = {\n",
    "        \"parent_text\": parent.page_content,\n",
    "        \"parent_id\": i,\n",
    "        \"parent_embedding\": embeddings.embed_query(parent.page_content),\n",
    "        \"children\": [\n",
    "            {\n",
    "                \"text\": c.page_content,\n",
    "                \"id\": f\"{i}-{ic}\",\n",
    "                \"embedding\": embeddings.embed_query(c.page_content),\n",
    "            }\n",
    "            for ic, c in enumerate(child_documents)\n",
    "        ],\n",
    "    }\n",
    "    # Ingest data\n",
    "    sleep(5)\n",
    "    graph.query(\n",
    "        \"\"\"\n",
    "    MERGE (p:Parent {id: $parent_id})\n",
    "    SET p.text = $parent_text\n",
    "    WITH p\n",
    "    CALL db.create.setVectorProperty(p, 'embedding', $parent_embedding)\n",
    "    YIELD node\n",
    "    WITH p \n",
    "    UNWIND $children AS child\n",
    "    MERGE (c:Child {id: child.id})\n",
    "    SET c.text = child.text\n",
    "    MERGE (c)<-[:HAS_CHILD]-(p)\n",
    "    WITH c, child\n",
    "    CALL db.create.setVectorProperty(c, 'embedding', child.embedding)\n",
    "    YIELD node\n",
    "    RETURN count(*)\n",
    "    \"\"\",\n",
    "        params,\n",
    "    )\n",
    "    # Create vector index for child\n",
    "    try:\n",
    "        graph.query(\n",
    "            \"CALL db.index.vector.createNodeIndex('parent_document', \"\n",
    "            \"'Child', 'embedding', $dimension, 'cosine')\",\n",
    "            {\"dimension\": embedding_dimension},\n",
    "        )\n",
    "    except ClientError:  # already exists\n",
    "        pass\n",
    "    # Create vector index for parents\n",
    "    try:\n",
    "        graph.query(\n",
    "            \"CALL db.index.vector.createNodeIndex('typical_rag', \"\n",
    "            \"'Parent', 'embedding', $dimension, 'cosine')\",\n",
    "            {\"dimension\": embedding_dimension},\n",
    "        )\n",
    "    except ClientError:  # already exists\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5ba4cb8a-ff21-4b71-aa87-c7bf5bc40cc8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Ingest hypothethical questions\n",
    "class Questions(BaseModel):\n",
    "    \"\"\"Generating hypothetical questions about text.\"\"\"\n",
    "\n",
    "    questions: List[str] = Field(\n",
    "        ...,\n",
    "        description=(\n",
    "            \"Generated hypothetical questions based on \" \"the information from the text\"\n",
    "        ),\n",
    "    )\n",
    "\n",
    "\n",
    "questions_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            (\n",
    "                \"You are generating hypothetical questions based on the information \"\n",
    "                \"found in the text and must reply in JSON format. Make sure to provide full context in the generated \"\n",
    "                \"questions.\"\n",
    "            ),\n",
    "        ),\n",
    "        (\n",
    "            \"human\",\n",
    "            (\n",
    "                \"Use the given format to generate hypothetical questions from the\"\n",
    "                \"following input: {input}\"\n",
    "            ),\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "question_chain = questions_prompt | llm.with_structured_output(Questions.json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ead14912-437f-44eb-b076-a3b8fa473b32",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "# class Joke(BaseModel):\n",
    "#     setup: str = Field(description=\"The setup of the joke\")\n",
    "#     punchline: str = Field(description=\"The punchline to the joke\")\n",
    "       \n",
    "# structured_llm = llm.with_structured_output(Joke.json)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "61a7ab3c-fe32-47c4-a561-505d34cdc3bd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# structured_llm.invoke(\n",
    "#     \"Tell me a joke about cats, respond in JSON with `setup` and `punchline` keys\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "11a6f3ca-736e-4099-8d73-58f27ca97a0d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def clean_questions_data(questions_data):\n",
    "    if 'questions' not in questions_data:\n",
    "        return []\n",
    "\n",
    "    cleaned_questions = []\n",
    "    for entry in questions_data['questions']:\n",
    "        if isinstance(entry, dict) and 'question' in entry:\n",
    "            cleaned_questions.append(entry)\n",
    "        elif isinstance(entry, str):\n",
    "            cleaned_questions.append({'question': entry})\n",
    "        else:\n",
    "            # Handle cases where the entry is not a string or doesn't contain the 'question' key\n",
    "            print(f\"Invalid entry found and skipped: {entry}\")\n",
    "    \n",
    "    return cleaned_questions\n",
    "\n",
    "for i, parent in enumerate(parent_documents):\n",
    "    questions_data = question_chain.invoke(parent.page_content)\n",
    "    cleaned_questions_list = clean_questions_data(questions_data)  \n",
    "    if 'questions' in questions_data:\n",
    "        questions_list = questions_data['questions']  # Access the 'questions' list\n",
    "        params = {\n",
    "            \"parent_id\": i,\n",
    "            \"questions\": []\n",
    "        }\n",
    "        \n",
    "        for iq, q in enumerate(cleaned_questions_list):  # Use the cleaned questions list\n",
    "            if isinstance(q, dict) and 'question' in q:\n",
    "                try:\n",
    "                    question_text = q['question']\n",
    "                    embedding = embeddings.embed_query(question_text)\n",
    "                    params[\"questions\"].append({\"text\": question_text, \"id\": f\"{i}-{iq}\", \"embedding\": embedding})\n",
    "                except Exception as e:\n",
    "                    print(f\"Error embedding question {q}: {e}\")\n",
    "            else:\n",
    "                print(f\"Skipping invalid question entry: {q}\")\n",
    "        \n",
    "        sleep(5)\n",
    "        graph.query(\n",
    "            \"\"\"\n",
    "        MERGE (p:Parent {id: $parent_id})\n",
    "        WITH p\n",
    "        UNWIND $questions AS question\n",
    "        CREATE (q:Question {id: question.id})\n",
    "        SET q.text = question.text\n",
    "        MERGE (q)<-[:HAS_QUESTION]-(p)\n",
    "        WITH q, question\n",
    "        CALL db.create.setVectorProperty(q, 'embedding', question.embedding)\n",
    "        YIELD node\n",
    "        RETURN count(*)\n",
    "        \"\"\",\n",
    "            params,\n",
    "        )\n",
    "        # Create vector index\n",
    "        try:\n",
    "            graph.query(\n",
    "                \"CALL db.index.vector.createNodeIndex('hypothetical_questions', \"\n",
    "                \"'Question', 'embedding', $dimension, 'cosine')\",\n",
    "                {\"dimension\": embedding_dimension},\n",
    "            )\n",
    "        except ClientError:  # already exists\n",
    "            pass\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5e4d1a9d-e1a0-4594-9383-59a5620defbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ingest summaries\n",
    "\n",
    "summary_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            (\n",
    "                \"You are generating concise and accurate summaries based on the \"\n",
    "                \"information found in the text. Do not miss in the summaries any information\" \n",
    "                \"related with numbers such as dates, costs, rates, porcentages or any sort of numerical values \"\n",
    "            ),\n",
    "        ),\n",
    "        (\n",
    "            \"human\",\n",
    "            (\"Generate a summary of the following input: {question}\\n\" \"Summary:\"),\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "summary_chain = summary_prompt | llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "814a4613-b6c2-454d-9851-4bf350c54303",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for i, parent in enumerate(parent_documents):\n",
    "    summary = summary_chain.invoke({\"question\": parent.page_content}).content\n",
    "    params = {\n",
    "        \"parent_id\": i,\n",
    "        \"summary\": summary,\n",
    "        \"embedding\": embeddings.embed_query(summary),\n",
    "    }\n",
    "    \n",
    "    sleep(5)\n",
    "    graph.query(\n",
    "        \"\"\"\n",
    "    MERGE (p:Parent {id: $parent_id})\n",
    "    MERGE (p)-[:HAS_SUMMARY]->(s:Summary)\n",
    "    SET s.text = $summary\n",
    "    WITH s\n",
    "    CALL db.create.setVectorProperty(s, 'embedding', $embedding)\n",
    "    YIELD node\n",
    "    RETURN count(*)\n",
    "    \"\"\",\n",
    "        params,\n",
    "    )\n",
    "    # Create vector index\n",
    "    try:\n",
    "        graph.query(\n",
    "            \"CALL db.index.vector.createNodeIndex('summary', \"\n",
    "            \"'Summary', 'embedding', $dimension, 'cosine')\",\n",
    "            {\"dimension\": embedding_dimension},\n",
    "        )\n",
    "    except ClientError:  # already exists\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7a42ed9b-b438-4478-b3f3-f091f9525eb5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import Neo4jVector\n",
    "\n",
    "\n",
    "\n",
    "# Typical RAG retriever\n",
    "\n",
    "typical_rag = Neo4jVector.from_existing_index(\n",
    "    embeddings, index_name=\"typical_rag\"\n",
    ")\n",
    "\n",
    "# Parent retriever\n",
    "\n",
    "parent_query = \"\"\"\n",
    "MATCH (node)<-[:HAS_CHILD]-(parent)\n",
    "WITH parent, max(score) AS score // deduplicate parents\n",
    "RETURN parent.text AS text, score, {} AS metadata LIMIT 1\n",
    "\"\"\"\n",
    "\n",
    "parent_vectorstore = Neo4jVector.from_existing_index(\n",
    "    embeddings,\n",
    "    index_name=\"parent_document\",\n",
    "    retrieval_query=parent_query,\n",
    ")\n",
    "\n",
    "# Hypothetic questions retriever\n",
    "\n",
    "hypothetic_question_query = \"\"\"\n",
    "MATCH (node)<-[:HAS_QUESTION]-(parent)\n",
    "WITH parent, max(score) AS score // deduplicate parents\n",
    "RETURN parent.text AS text, score, {} AS metadata\n",
    "\"\"\"\n",
    "\n",
    "hypothetic_question_vectorstore = Neo4jVector.from_existing_index(\n",
    "    embeddings,\n",
    "    index_name=\"hypothetical_questions\",\n",
    "    retrieval_query=hypothetic_question_query,\n",
    ")\n",
    "# Summary retriever\n",
    "\n",
    "summary_query = \"\"\"\n",
    "MATCH (node)<-[:HAS_SUMMARY]-(parent)\n",
    "WITH parent, max(score) AS score // deduplicate parents\n",
    "RETURN parent.text AS text, score, {} AS metadata\n",
    "\"\"\"\n",
    "\n",
    "summary_vectorstore = Neo4jVector.from_existing_index(\n",
    "    embeddings,\n",
    "    index_name=\"summary\",\n",
    "    retrieval_query=summary_query,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9dc5bdd3-be56-4927-a075-4a3d62a5423e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Biden administration is poised to make a landmark change to the federal government's position on marijuana with a proposed plan that would no longer consider marijuana among the most dangerous and addictive substances. \n",
      "\n",
      "In what would be the biggest change in marijuana policy the federal government has taken since pot was first outlawed, the Drug Enforcement Administration will take public comments on a plan to recategorize marijuana under the Controlled Substances Act, according to a source familiar with the process. The news was first reported by The Associated Press.\n",
      "\n",
      "The Department of Justice will send its recommendation to reclassify marijuana from a Schedule I drug to a Schedule III drug to the White House Office of Management and Budget, according to the source, who was not authorized to speak publicly. The Justice Department is expected to transmit the recommendation today, the source said.\n",
      "\n",
      "The plan wouldn't legalize marijuana at the federal level outright, but it would reclassify it from a Schedule I drug – believed highly dangerous, addictive and without medical use – to a Schedule III drug that can be lawfully prescribed as medication. Marijuana has been a Schedule I drug since the Controlled Substances Act was signed in 1970.\n",
      "\n",
      "“It is significant for these federal agencies, and the DEA and FDA in particular, to acknowledge publicly for the first time what many patients and advocates have known for decades: that cannabis is a safe and effective therapeutic agent for tens of millions of Americans,\" said Paul Armentano, deputy director of the National Organization for the Reform of Marijuana Laws, or NORML, which advocates for cannabis to be removed altogether from the list of controlled substances.\n",
      "\n",
      "This bureaucratic move is only a small step toward what advocates hope will be full legalization of the drug. However, the new proposed classification does not fully address the inconsistencies between federal restrictions and the laws in a growing number of states that have authorized medical and recreational use of pot. \n",
      "\n",
      "�\n"
     ]
    }
   ],
   "source": [
    "response = hypothetic_question_vectorstore.similarity_search(\n",
    "    \"What is The Department of Justice recommendation on marijuana\"\n",
    ")\n",
    "print(response[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "319aa15c-64ca-492a-81e1-6697a2386d2e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': 'Which other drugs appear along with marijuana in the Schedule I',\n",
       " 'result': 'Marijuana has been listed under the Controlled Substances Act as a Schedule I drug, alongside heroin, LSD, and ecstasy.'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "from langchain.chat_models import AzureChatOpenAI\n",
    "\n",
    "graph.refresh_schema()\n",
    "\n",
    "vector_qa = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=typical_rag.as_retriever()\n",
    ")\n",
    "\n",
    "vector_qa.invoke(\n",
    "     \"Which other drugs appear along with marijuana in the Schedule I\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2e9fe107-6bee-47d2-ac5d-876f767ba4a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': 'What experts  exposed to USA TODAY on marijuana',\n",
       " 'result': \"Experts exposed to USA TODAY that marijuana’s placement on Schedule I was not based on credible scientific evidence of its perils, but once it was listed, researchers and advocates faced a heavy burden trying to prove it shouldn’t face such stiff restrictions. They also said that rescheduling is a step forward, but it is not nearly enough, and there's no reason to keep cannabis in the Controlled Substances Act.\"}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.refresh_schema()\n",
    "\n",
    "vector_qa = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=typical_rag.as_retriever()\n",
    ")\n",
    "\n",
    "vector_qa.invoke(\n",
    "    #\"What Wexler previously told to USA TODAY\"\n",
    "    \"What experts  exposed to USA TODAY on marijuana\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "888d3395-99ee-4755-8d81-e91cb7df310b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lriospie\\AppData\\Local\\anaconda3\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:119: LangChainDeprecationWarning: The class `AzureChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 0.3.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import AzureChatOpenAI`.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import GraphCypherQAChain\n",
    "\n",
    "# graph = Neo4jGraph()\n",
    "graph.refresh_schema()\n",
    "\n",
    "cypher_chain = GraphCypherQAChain.from_llm(\n",
    "    cypher_llm = AzureChatOpenAI(azure_deployment='Chat_gpt_4',api_version=\"2023-05-15\", temperature=0),\n",
    "    qa_llm = AzureChatOpenAI(azure_deployment='chat_gtp_35',api_version=\"2023-05-15\", temperature=0), graph=graph, verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "26494579-3163-4572-a250-9be0807ae114",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new GraphCypherQAChain chain...\u001b[0m\n",
      "Generated Cypher:\n",
      "\u001b[32;1m\u001b[1;3mcypher\n",
      "MATCH (p:Parent)-[:HAS_CHILD|:HAS_QUESTION|:HAS_SUMMARY]->(n)\n",
      "WHERE n.text CONTAINS 'Schedule III'\n",
      "RETURN COUNT(n) AS ScheduleIIIMentions\n",
      "\u001b[0m\n",
      "Full Context:\n",
      "\u001b[32;1m\u001b[1;3m[{'ScheduleIIIMentions': 15}]\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'query': 'How many times Schedule III is mentioned within the text',\n",
       " 'result': 'Schedule III is mentioned 15 times within the text.'}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.refresh_schema()\n",
    "cypher_chain.invoke(\n",
    "     \"How many times Schedule III is mentioned within the text\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ce02c064-5d6e-45d3-954d-8a05a5ff91e2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.agents import initialize_agent, Tool\n",
    "from langchain.agents import AgentType\n",
    "\n",
    "graph = Neo4jGraph()\n",
    "graph.refresh_schema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b29d7504-4edd-4ec9-b788-b685d1cb652d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lriospie\\AppData\\Local\\anaconda3\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:119: LangChainDeprecationWarning: The function `initialize_agent` was deprecated in LangChain 0.1.0 and will be removed in 0.3.0. Use Use new agent constructor methods like create_react_agent, create_json_agent, create_structured_chat_agent, etc. instead.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "tools = [\n",
    "    Tool(\n",
    "        name=\"Tasks\",\n",
    "        func=vector_qa.run,\n",
    "        description=\"\"\"Useful to reply to most of the queries as long as any sort of aggregation is not requested.\n",
    "        Use full question as input.\n",
    "        \"\"\",\n",
    "    ),\n",
    "    Tool(\n",
    "        name=\"Graph\",\n",
    "        func=cypher_chain.run,\n",
    "        description=\"\"\"Usfeful when any sort of aggregation is requested in the query.\n",
    "        Use full question as input.\n",
    "        \"\"\",\n",
    "    ),\n",
    "]\n",
    "\n",
    "mrkl = initialize_agent(\n",
    "    tools, \n",
    "    AzureChatOpenAI(azure_deployment='Chat_gpt_4',api_version=\"2023-05-15\", temperature=0),\n",
    "    agent=AgentType.OPENAI_FUNCTIONS, verbose=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a046490e-0d7e-4341-be28-cd47524a5674",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `Tasks` with `How many times Schedule III is mentioned within the text`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3mSchedule III is mentioned 7 times within the text.\u001b[0m\u001b[32;1m\u001b[1;3mSchedule III is mentioned 7 times within the text.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "{'input': 'How many times Schedule III is mentioned within the text', 'output': 'Schedule III is mentioned 7 times within the text.'}\n"
     ]
    }
   ],
   "source": [
    "response = mrkl.invoke(\"How many times Schedule III is mentioned within the text\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ecaafff0-b7c9-44c5-87fb-382fcb03bc37",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `Tasks` with `Who might be affected with IQ loss due to marijuana consumption`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3mAccording to the National Institute on Drug Abuse, people who begin using marijuana at a young age may experience permanent IQ loss.\u001b[0m\u001b[32;1m\u001b[1;3mPeople who begin using marijuana at a young age may be affected with IQ loss, potentially experiencing permanent reductions in their IQ.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "{'input': 'Who might be affected with IQ loss due to marijuana consumption', 'output': 'People who begin using marijuana at a young age may be affected with IQ loss, potentially experiencing permanent reductions in their IQ.'}\n"
     ]
    }
   ],
   "source": [
    "response = mrkl.invoke(\"Who might be affected with IQ loss due to marijuana consumption\")\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
